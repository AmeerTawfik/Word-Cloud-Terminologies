{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "8eb161a9-46ad-43a5-a965-f97571f76098",
      "cell_type": "markdown",
      "source": "<center><b><font color='red' size=5>Word Cloud For Teminologies</font></b></center>",
      "metadata": {}
    },
    {
      "id": "2bc8dc10-e0b0-4d16-b066-4b832411750b",
      "cell_type": "markdown",
      "source": "---\n### An Introduction To The Problem. \"Background\"\n#### Given the subject book in plain-text form, we would like to get some terminologies out of the text book.\n#### We are interested in the terminologies which are in `Chapter #1`.",
      "metadata": {}
    },
    {
      "id": "3098c5e0-b5d6-4647-bedc-7d1e9d9c0397",
      "cell_type": "markdown",
      "source": "---\n## Table Of Contents:\n1. #### Importing Necessary Packages. [Go to T.1](#T.1)\n2. #### Formulate The Problem. [Go to T.2](#T.2)\n3. #### Preprocessing The Text. [Go to T.3](#T.3)\n4. #### Optional Step. [Go to T.4](#T.4)",
      "metadata": {}
    },
    {
      "id": "d4784284-dcff-42c1-a743-4f522074c047",
      "cell_type": "markdown",
      "source": "---\n<a id=\"T.1\"></a>\n### Importing Necessary Packages:\n#### We May Need Some Of The Following Packages, And Modules: \n* ##### Pandas\n* ##### Nltk\n* ##### Seaborn, MatplotLib\n* ##### Collections\n* ##### Wordcloud",
      "metadata": {
        "tags": []
      }
    },
    {
      "id": "35e8659a",
      "cell_type": "code",
      "source": "# Import Necessary Modules And Packages.\nimport wordcloud\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport pandas as pd\nimport re",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "372288c5-8b60-42f7-9501-ae98d1e930fd",
      "cell_type": "markdown",
      "source": "---\n<a id=\"T.2\"></a>\n### Formulate The Problem:\n#### In This Part, We Will Need To:\n* ##### Read The Text The Correct Way.\n* ##### Setup The Text For The Preprocessing Step.\n* ##### Have A General Look At The Text To Gain Some Insights.\n###### `PS:` To Get The Termonologies From The Desired Chapter, We Got Two Ways:\n1. ###### Extract The Text Of Chapter #1 From The Whole Text Book.\n2. ###### Extract The Section Of Terminologies In That Chapter From The Whole Book.",
      "metadata": {}
    },
    {
      "id": "626c7254-1f6c-466a-9ef8-8b172c4c54ea",
      "cell_type": "code",
      "source": "# Read The Book Text File Using Pandas \"read_csv\" Function, With Determining The \"delimiter\" Parameter To Be \"\\t\" Character.\ntext_book = pd.read_csv('Data mining.txt', delimiter='\\t', header=None)\ntext_book.rename(columns = {0:'Text'}, inplace = True)\ntext_book",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ba8707d5-e845-4c94-8336-9dadd97d3aa1",
      "cell_type": "code",
      "source": "# Get The Chapter 1 Text From The SBook.\nch1_mask = text_book['Text'].str.contains('1.1 What Is Business Analytics?')\nch1_index = list(text_book[ch1_mask].index)\nprint(\"Chapter 1 Occurences Indices:\",ch1_index)\n\nch2_mask = text_book['Text'].str.contains('2.1 Introduction')\nch2_index = list(text_book[ch2_mask].index)\nprint(\"Chapter 2 Occurences Indices:\",ch2_index)\n\nchapter_1 = (text_book.iloc[ch1_index[1]:ch2_index[2]]).reset_index()\nchapter_1.drop(['index'],axis=1,inplace=True)\nchapter_1",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9ce9a540-c06b-4ed5-9521-dbed0215b6d4",
      "cell_type": "code",
      "source": "# Get The Terminology Section From Chapter 1 Text.\nsect7_mask = text_book['Text'].str.contains('1.7 Terminology')\nsect7_index = list(text_book[sect7_mask].index)\nprint(\"Chapter 1 Section 7 Occurences Indices:\",sect7_index)\n\nsect8_mask = text_book['Text'].str.contains('1.8 Road Maps')\nsect8_index = list(text_book[sect8_mask].index)\nprint(\"Chapter 1 Section 8 Occurences Indices:\",sect8_index)\n\nterms_sect = (text_book.iloc[(sect7_index[1]+1):sect8_index[1]]).reset_index()\nterms_sect.drop(['index'],axis=1,inplace=True)\nterms_sect",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ee8e5600-418e-4961-85b2-cb2f62020f76",
      "cell_type": "markdown",
      "source": "---\n<a id=\"T.3\"></a>\n### Preprocessing The Text.\n#### In This Part, We Will Perform:\n* ##### Remove Numbers From The Text Using `Regular Expressions`.\n* ##### Remove Special Characters From The Text Using `Regular Expressions`.\n* ##### Tokenize The Text `Split The Sentence\\Text Into Individual Words List`.\n* ##### Remove The Stop Words From The Text.\n* ##### Generate A Word Cloud Of The Cleaned Text.",
      "metadata": {
        "tags": []
      }
    },
    {
      "id": "fcd047bf-fd1d-48e3-8bb0-a434c767d6e3",
      "cell_type": "code",
      "source": "# Preprocess The Text And Get A Word Cloud From It.\ntarget_text = \" \".join(chapter_1['Text'].values)\ndef preprocess_text(text_in):\n    text_prep = re.sub(r'[0-9]', '', text_in)\n    text_prep = re.sub(r'[^\\w\\s]', '', text_prep)\n    tokens = word_tokenize(text_prep)\n    stop_words = set(stopwords.words('english'))\n    terms = [word for word in tokens if word.istitle() and len(word) > 3]\n    terms_low = [word.lower() for word in terms]\n    terms_low = [word for word in terms_low if word not in stop_words]\n    return terms_low\ntext_prep = preprocess_text(target_text)\nprint(text_prep)\n\nword_counts = Counter(text_prep)\nwc = wordcloud.WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)\nplt.imshow(wc)\nplt.axis('off')\nplt.show()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d0d76cde-ce2c-4459-bf56-dfbbc2ac3265",
      "cell_type": "code",
      "source": "# Preprocess The Text And Get A Word Cloud From It.\ntarget_text = \" \".join(terms_sect['Text'].values)\ntext_prep = preprocess_text(target_text)\nprint(text_prep)\n\nword_counts = Counter(text_prep)\nwc = wordcloud.WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)\nplt.imshow(wc)\nplt.axis('off')\nplt.show()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "88348ee7-6a59-44f8-97fe-4397a5d14803",
      "cell_type": "markdown",
      "source": "---\n<a id=\"T.4\"></a>\n### Optional Step.\n#### In This Part, We Will Implement:\n* ##### Gensim `Phrases` Model, To Evaluate Possible Collocations Among The Extracted Terminologies.",
      "metadata": {}
    },
    {
      "id": "1f51377f-589e-4e1e-9b53-1ca14370de68",
      "cell_type": "code",
      "source": "# We Can Generate Collocations Using Gensim Model.\nfrom gensim.models import Phrases\nsentences_bytes = [[word.encode() for word in text_prep]]\nn_gram_model = Phrases(sentences_bytes, min_count=5, delimiter=b'_')  \ncollocations = [key.decode() for key in n_gram_model.vocab.keys() if b'_' in key]\nprint(collocations)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1125816b-cfd2-437c-8b75-637f7bacde7f",
      "cell_type": "code",
      "source": "# Generate Word Frequencies From The Collocations, Then Get A Word Cloud From It.\nword_freq = {}\nfor word in collocations:\n    if word in word_freq:\n        word_freq[word] += 1\n    else:\n        word_freq[word] = 1\nwc = wordcloud.WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\nplt.imshow(wc) \nplt.axis(\"off\") \nplt.show() ",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "34209ee8-67bc-4286-810e-afa8d9927bf7",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}